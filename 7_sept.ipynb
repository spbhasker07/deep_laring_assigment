{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "260c6893-7689-4b52-a3bc-238665f3bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eac84b0-bd30-41bf-bfc1-f66e87795d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fff059-a0d9-4112-b54c-4322f6b4d35e",
   "metadata": {},
   "source": [
    "# Perceptron network for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92ad97bc-fa0c-4eb0-a266-31f59182d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3600 - loss: 2.8661 \n",
      "Epoch 2/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - loss: 1.1374\n",
      "Epoch 3/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4867 - loss: 1.0587 \n",
      "Epoch 4/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6000 - loss: 0.9792 \n",
      "Epoch 5/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6467 - loss: 0.9374 \n",
      "Epoch 6/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6267 - loss: 0.8999 \n",
      "Epoch 7/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6267 - loss: 0.8686 \n",
      "Epoch 8/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6267 - loss: 0.8415 \n",
      "Epoch 9/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6267 - loss: 0.8174\n",
      "Epoch 10/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6467 - loss: 0.7954\n",
      "Epoch 11/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6467 - loss: 0.7747 \n",
      "Epoch 12/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6533 - loss: 0.7551\n",
      "Epoch 13/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6733 - loss: 0.7361 \n",
      "Epoch 14/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6733 - loss: 0.7175 \n",
      "Epoch 15/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6800 - loss: 0.6993\n",
      "Epoch 16/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6800 - loss: 0.6812\n",
      "Epoch 17/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6933 - loss: 0.6631 \n",
      "Epoch 18/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7000 - loss: 0.6450 \n",
      "Epoch 19/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7067 - loss: 0.6268 \n",
      "Epoch 20/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7133 - loss: 0.6085 \n",
      "Epoch 21/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7267 - loss: 0.5900 \n",
      "Epoch 22/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7400 - loss: 0.5713\n",
      "Epoch 23/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7533 - loss: 0.5524 \n",
      "Epoch 24/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7600 - loss: 0.5334\n",
      "Epoch 25/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.5144 \n",
      "Epoch 26/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7800 - loss: 0.4955 \n",
      "Epoch 27/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7867 - loss: 0.4769 \n",
      "Epoch 28/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7933 - loss: 0.4590 \n",
      "Epoch 29/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7933 - loss: 0.4419\n",
      "Epoch 30/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8133 - loss: 0.4259 \n",
      "Epoch 31/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8267 - loss: 0.4113 \n",
      "Epoch 32/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.3982 \n",
      "Epoch 33/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8467 - loss: 0.3865\n",
      "Epoch 34/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8600 - loss: 0.3762\n",
      "Epoch 35/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8667 - loss: 0.3669 \n",
      "Epoch 36/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.3586 \n",
      "Epoch 37/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8800 - loss: 0.3510 \n",
      "Epoch 38/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8933 - loss: 0.3441 \n",
      "Epoch 39/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.3376 \n",
      "Epoch 40/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8933 - loss: 0.3316 \n",
      "Epoch 41/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.3259 \n",
      "Epoch 42/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9067 - loss: 0.3206 \n",
      "Epoch 43/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9067 - loss: 0.3155 \n",
      "Epoch 44/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9133 - loss: 0.3107 \n",
      "Epoch 45/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9133 - loss: 0.3061\n",
      "Epoch 46/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.3017  \n",
      "Epoch 47/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9200 - loss: 0.2974\n",
      "Epoch 48/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9200 - loss: 0.2934 \n",
      "Epoch 49/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9200 - loss: 0.2895 \n",
      "Epoch 50/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9200 - loss: 0.2857\n",
      "Epoch 51/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9267 - loss: 0.2821 \n",
      "Epoch 52/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9267 - loss: 0.2786\n",
      "Epoch 53/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9267 - loss: 0.2752\n",
      "Epoch 54/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2720\n",
      "Epoch 55/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2688 \n",
      "Epoch 56/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2657 \n",
      "Epoch 57/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2628 \n",
      "Epoch 58/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.2599 \n",
      "Epoch 59/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9333 - loss: 0.2571 \n",
      "Epoch 60/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2544 \n",
      "Epoch 61/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9333 - loss: 0.2518\n",
      "Epoch 62/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9333 - loss: 0.2492 \n",
      "Epoch 63/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2467 \n",
      "Epoch 64/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2443 \n",
      "Epoch 65/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2419\n",
      "Epoch 66/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.2396\n",
      "Epoch 67/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2374\n",
      "Epoch 68/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9333 - loss: 0.2352\n",
      "Epoch 69/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2331 \n",
      "Epoch 70/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.2311\n",
      "Epoch 71/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9333 - loss: 0.2290\n",
      "Epoch 72/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9333 - loss: 0.2271\n",
      "Epoch 73/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2252 \n",
      "Epoch 74/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2233\n",
      "Epoch 75/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2215\n",
      "Epoch 76/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9333 - loss: 0.2197\n",
      "Epoch 77/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.2180\n",
      "Epoch 78/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.2163 \n",
      "Epoch 79/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2146 \n",
      "Epoch 80/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2130 \n",
      "Epoch 81/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9400 - loss: 0.2114\n",
      "Epoch 82/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9400 - loss: 0.2099\n",
      "Epoch 83/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.2084 \n",
      "Epoch 84/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.2069\n",
      "Epoch 85/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.2055 \n",
      "Epoch 86/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9467 - loss: 0.2040\n",
      "Epoch 87/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9467 - loss: 0.2027\n",
      "Epoch 88/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9467 - loss: 0.2013 \n",
      "Epoch 89/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.2000 \n",
      "Epoch 90/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1987\n",
      "Epoch 91/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1974\n",
      "Epoch 92/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.1962 \n",
      "Epoch 93/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.1949\n",
      "Epoch 94/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.1937 \n",
      "Epoch 95/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.1926 \n",
      "Epoch 96/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.1914\n",
      "Epoch 97/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.1903 \n",
      "Epoch 98/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9467 - loss: 0.1892 \n",
      "Epoch 99/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.1881\n",
      "Epoch 100/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9533 - loss: 0.1870\n",
      "Epoch 101/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1860 \n",
      "Epoch 102/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9533 - loss: 0.1850\n",
      "Epoch 103/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.1840\n",
      "Epoch 104/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1830\n",
      "Epoch 105/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9600 - loss: 0.1820\n",
      "Epoch 106/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1810\n",
      "Epoch 107/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1801\n",
      "Epoch 108/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1792\n",
      "Epoch 109/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1783\n",
      "Epoch 110/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1774\n",
      "Epoch 111/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9600 - loss: 0.1765\n",
      "Epoch 112/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9600 - loss: 0.1757\n",
      "Epoch 113/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9600 - loss: 0.1748\n",
      "Epoch 114/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1740\n",
      "Epoch 115/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1732\n",
      "Epoch 116/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1724\n",
      "Epoch 117/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1716\n",
      "Epoch 118/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1708\n",
      "Epoch 119/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9600 - loss: 0.1700\n",
      "Epoch 120/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1693\n",
      "Epoch 121/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9600 - loss: 0.1686\n",
      "Epoch 122/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1678\n",
      "Epoch 123/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1671\n",
      "Epoch 124/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9600 - loss: 0.1664 \n",
      "Epoch 125/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.1657 \n",
      "Epoch 126/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1650\n",
      "Epoch 127/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1643\n",
      "Epoch 128/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1637\n",
      "Epoch 129/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9667 - loss: 0.1630\n",
      "Epoch 130/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9667 - loss: 0.1624\n",
      "Epoch 131/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9667 - loss: 0.1617\n",
      "Epoch 132/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1611\n",
      "Epoch 133/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1605\n",
      "Epoch 134/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1599 \n",
      "Epoch 135/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1593\n",
      "Epoch 136/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1587\n",
      "Epoch 137/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1581\n",
      "Epoch 138/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1575\n",
      "Epoch 139/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1570\n",
      "Epoch 140/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1564 \n",
      "Epoch 141/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1558\n",
      "Epoch 142/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1553 \n",
      "Epoch 143/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1548\n",
      "Epoch 144/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1542\n",
      "Epoch 145/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1537 \n",
      "Epoch 146/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1532\n",
      "Epoch 147/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1527 \n",
      "Epoch 148/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1522 \n",
      "Epoch 149/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1517 \n",
      "Epoch 150/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1512 \n",
      "Epoch 151/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1507\n",
      "Epoch 152/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1502 \n",
      "Epoch 153/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1497\n",
      "Epoch 154/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1493\n",
      "Epoch 155/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1488\n",
      "Epoch 156/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1483\n",
      "Epoch 157/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1479\n",
      "Epoch 158/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9667 - loss: 0.1474\n",
      "Epoch 159/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9667 - loss: 0.1470\n",
      "Epoch 160/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1466 \n",
      "Epoch 161/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1461 \n",
      "Epoch 162/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1457 \n",
      "Epoch 163/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1453\n",
      "Epoch 164/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1449\n",
      "Epoch 165/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1444 \n",
      "Epoch 166/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1440\n",
      "Epoch 167/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9667 - loss: 0.1436\n",
      "Epoch 168/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9667 - loss: 0.1432\n",
      "Epoch 169/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1428 \n",
      "Epoch 170/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1424 \n",
      "Epoch 171/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1421 \n",
      "Epoch 172/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1417 \n",
      "Epoch 173/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1413 \n",
      "Epoch 174/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1409\n",
      "Epoch 175/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1406 \n",
      "Epoch 176/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1402 \n",
      "Epoch 177/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1398\n",
      "Epoch 178/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1395 \n",
      "Epoch 179/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1391  \n",
      "Epoch 180/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1388 \n",
      "Epoch 181/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1384 \n",
      "Epoch 182/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1381 \n",
      "Epoch 183/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1377 \n",
      "Epoch 184/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1374 \n",
      "Epoch 185/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1371 \n",
      "Epoch 186/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1367 \n",
      "Epoch 187/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1364 \n",
      "Epoch 188/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1361 \n",
      "Epoch 189/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1358 \n",
      "Epoch 190/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1354 \n",
      "Epoch 191/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1351 \n",
      "Epoch 192/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1348 \n",
      "Epoch 193/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1345 \n",
      "Epoch 194/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1342 \n",
      "Epoch 195/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1339 \n",
      "Epoch 196/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1336 \n",
      "Epoch 197/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1333 \n",
      "Epoch 198/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1330 \n",
      "Epoch 199/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.1327 \n",
      "Epoch 200/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9733 - loss: 0.1324 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197b74e34d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.1),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b8199b4-a0a1-416d-bdf3-b11a19b1df57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses=model.history.history['loss']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,201),losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b841310-f121-465b-b6c0-291a3176a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "[[0.00260226 0.5053309  0.49206686]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_sample=np.array([4.5,1.2,5.8,.2],dtype=np.float32)\n",
    "\n",
    "print(model.predict(new_sample.reshape(1,4)))\n",
    "print(np.argmax(model.predict(new_sample.reshape(1,4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed56f2-2733-40b6-9c3b-bc469292a6a1",
   "metadata": {},
   "source": [
    "# Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da30f45e-1026-4d9a-afaf-489a718f7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3467 - loss: 2.6094  \n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5933 - loss: 0.8339 \n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6667 - loss: 0.5894\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7000 - loss: 0.5355 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7200 - loss: 0.5028 \n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7400 - loss: 0.4769 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.4515 \n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.4337 \n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7867 - loss: 0.4202 \n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8067 - loss: 0.4077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197b9b8b0e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#add hidden layer\n",
    "model.add(Dense(units=50,activation='relu'))\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.1),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "800cb4d8-251f-4f47-9721-3f4c593b2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3400 - loss: 1.7224  \n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6267 - loss: 0.8163\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7467 - loss: 0.6456 \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7400 - loss: 0.5445 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7733 - loss: 0.4935\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7733 - loss: 0.4695 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7733 - loss: 0.4612\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7467 - loss: 0.4539 \n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7467 - loss: 0.4365\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7800 - loss: 0.4155 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197bae2f700>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#add hidden layer\n",
    "model.add(Dense(units=50,activation='relu'))\n",
    "\n",
    "#add one more hidden layer\n",
    "model.add(Dense(units=25,activation='relu'))\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.1),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c54c1-3f92-4950-8f66-0f6f73b4bede",
   "metadata": {},
   "source": [
    "# DNN(more than 2 hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58107461-65cc-4b71-ad6b-0278e90cefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4067 - loss: 1.1706  \n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6667 - loss: 0.7733\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6467 - loss: 0.6676 \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6133 - loss: 0.5948 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6067 - loss: 0.5296\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6133 - loss: 0.5391 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5600 - loss: 0.7481 \n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7200 - loss: 0.4886 \n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.4674 \n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7533 - loss: 0.4479 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197c0b6be70>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#add hidden layer-1\n",
    "model.add(Dense(units=50,activation='relu',kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "\n",
    "#add one more hidden layer-2\n",
    "model.add(Dense(units=25,activation='relu'))\n",
    "\n",
    "#add one more hidden layer-3\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.1),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3649716-592b-41c2-970d-79e9c124ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6667 - loss: 0.8479 - val_accuracy: 0.0000e+00 - val_loss: 1.9354\n",
      "Epoch 2/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8333 - loss: 0.6550 - val_accuracy: 0.0000e+00 - val_loss: 1.7053\n",
      "Epoch 3/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8333 - loss: 0.5551 - val_accuracy: 0.0000e+00 - val_loss: 1.5682\n",
      "Epoch 4/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8333 - loss: 0.4958 - val_accuracy: 0.0000e+00 - val_loss: 1.5252\n",
      "Epoch 5/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8333 - loss: 0.4570 - val_accuracy: 0.0000e+00 - val_loss: 1.5092\n",
      "Epoch 6/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8333 - loss: 0.4285 - val_accuracy: 0.0000e+00 - val_loss: 1.5029\n",
      "Epoch 7/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8333 - loss: 0.4053 - val_accuracy: 0.0000e+00 - val_loss: 1.5056\n",
      "Epoch 8/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8583 - loss: 0.3846 - val_accuracy: 0.0000e+00 - val_loss: 1.5308\n",
      "Epoch 9/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8667 - loss: 0.3691 - val_accuracy: 0.0000e+00 - val_loss: 1.5595\n",
      "Epoch 10/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8667 - loss: 0.3580 - val_accuracy: 0.0000e+00 - val_loss: 1.5826\n",
      "Epoch 11/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8583 - loss: 0.3487 - val_accuracy: 0.0000e+00 - val_loss: 1.6029\n",
      "Epoch 12/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8583 - loss: 0.3408 - val_accuracy: 0.0000e+00 - val_loss: 1.6205\n",
      "Epoch 13/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8583 - loss: 0.3338 - val_accuracy: 0.0000e+00 - val_loss: 1.6340\n",
      "Epoch 14/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8667 - loss: 0.3273 - val_accuracy: 0.0000e+00 - val_loss: 1.6423\n",
      "Epoch 15/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8500 - loss: 0.3211 - val_accuracy: 0.0000e+00 - val_loss: 1.6459\n",
      "Epoch 16/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8500 - loss: 0.3151 - val_accuracy: 0.0000e+00 - val_loss: 1.6462\n",
      "Epoch 17/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8583 - loss: 0.3093 - val_accuracy: 0.0000e+00 - val_loss: 1.6446\n",
      "Epoch 18/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8500 - loss: 0.3038 - val_accuracy: 0.0000e+00 - val_loss: 1.6421\n",
      "Epoch 19/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8500 - loss: 0.2987 - val_accuracy: 0.0000e+00 - val_loss: 1.6392\n",
      "Epoch 20/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8500 - loss: 0.2938 - val_accuracy: 0.0000e+00 - val_loss: 1.6360\n",
      "Epoch 21/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8500 - loss: 0.2892 - val_accuracy: 0.0000e+00 - val_loss: 1.6326\n",
      "Epoch 22/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8500 - loss: 0.2849 - val_accuracy: 0.0000e+00 - val_loss: 1.6289\n",
      "Epoch 23/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8583 - loss: 0.2808 - val_accuracy: 0.0000e+00 - val_loss: 1.6247\n",
      "Epoch 24/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8583 - loss: 0.2768 - val_accuracy: 0.0000e+00 - val_loss: 1.6201\n",
      "Epoch 25/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8667 - loss: 0.2730 - val_accuracy: 0.0000e+00 - val_loss: 1.6149\n",
      "Epoch 26/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8667 - loss: 0.2693 - val_accuracy: 0.0000e+00 - val_loss: 1.6092\n",
      "Epoch 27/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8667 - loss: 0.2657 - val_accuracy: 0.0000e+00 - val_loss: 1.6028\n",
      "Epoch 28/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8667 - loss: 0.2621 - val_accuracy: 0.0000e+00 - val_loss: 1.5958\n",
      "Epoch 29/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8667 - loss: 0.2586 - val_accuracy: 0.0000e+00 - val_loss: 1.5882\n",
      "Epoch 30/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8667 - loss: 0.2552 - val_accuracy: 0.0000e+00 - val_loss: 1.5799\n",
      "Epoch 31/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.2517 - val_accuracy: 0.0000e+00 - val_loss: 1.5710\n",
      "Epoch 32/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8833 - loss: 0.2483 - val_accuracy: 0.0000e+00 - val_loss: 1.5614\n",
      "Epoch 33/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8833 - loss: 0.2450 - val_accuracy: 0.0000e+00 - val_loss: 1.5513\n",
      "Epoch 34/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8833 - loss: 0.2416 - val_accuracy: 0.0000e+00 - val_loss: 1.5405\n",
      "Epoch 35/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8833 - loss: 0.2383 - val_accuracy: 0.0000e+00 - val_loss: 1.5292\n",
      "Epoch 36/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8833 - loss: 0.2350 - val_accuracy: 0.0000e+00 - val_loss: 1.5174\n",
      "Epoch 37/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8833 - loss: 0.2316 - val_accuracy: 0.0000e+00 - val_loss: 1.5050\n",
      "Epoch 38/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8833 - loss: 0.2283 - val_accuracy: 0.0333 - val_loss: 1.4922\n",
      "Epoch 39/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8833 - loss: 0.2250 - val_accuracy: 0.0333 - val_loss: 1.4788\n",
      "Epoch 40/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8833 - loss: 0.2216 - val_accuracy: 0.0333 - val_loss: 1.4651\n",
      "Epoch 41/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8833 - loss: 0.2183 - val_accuracy: 0.0667 - val_loss: 1.4509\n",
      "Epoch 42/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8833 - loss: 0.2150 - val_accuracy: 0.0667 - val_loss: 1.4364\n",
      "Epoch 43/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8833 - loss: 0.2116 - val_accuracy: 0.0667 - val_loss: 1.4216\n",
      "Epoch 44/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8833 - loss: 0.2083 - val_accuracy: 0.1000 - val_loss: 1.4065\n",
      "Epoch 45/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8917 - loss: 0.2049 - val_accuracy: 0.1000 - val_loss: 1.3911\n",
      "Epoch 46/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8917 - loss: 0.2016 - val_accuracy: 0.1000 - val_loss: 1.3755\n",
      "Epoch 47/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8917 - loss: 0.1982 - val_accuracy: 0.1333 - val_loss: 1.3596\n",
      "Epoch 48/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8917 - loss: 0.1948 - val_accuracy: 0.1333 - val_loss: 1.3437\n",
      "Epoch 49/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8917 - loss: 0.1915 - val_accuracy: 0.1667 - val_loss: 1.3276\n",
      "Epoch 50/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8917 - loss: 0.1881 - val_accuracy: 0.2000 - val_loss: 1.3114\n",
      "Epoch 51/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9000 - loss: 0.1848 - val_accuracy: 0.2000 - val_loss: 1.2951\n",
      "Epoch 52/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9083 - loss: 0.1814 - val_accuracy: 0.2333 - val_loss: 1.2788\n",
      "Epoch 53/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9167 - loss: 0.1781 - val_accuracy: 0.2667 - val_loss: 1.2625\n",
      "Epoch 54/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9167 - loss: 0.1748 - val_accuracy: 0.2667 - val_loss: 1.2463\n",
      "Epoch 55/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9167 - loss: 0.1715 - val_accuracy: 0.2667 - val_loss: 1.2301\n",
      "Epoch 56/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9250 - loss: 0.1682 - val_accuracy: 0.2667 - val_loss: 1.2140\n",
      "Epoch 57/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9250 - loss: 0.1650 - val_accuracy: 0.3333 - val_loss: 1.1981\n",
      "Epoch 58/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9333 - loss: 0.1618 - val_accuracy: 0.3333 - val_loss: 1.1823\n",
      "Epoch 59/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9333 - loss: 0.1586 - val_accuracy: 0.3333 - val_loss: 1.1667\n",
      "Epoch 60/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9333 - loss: 0.1555 - val_accuracy: 0.3333 - val_loss: 1.1514\n",
      "Epoch 61/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9333 - loss: 0.1524 - val_accuracy: 0.3667 - val_loss: 1.1363\n",
      "Epoch 62/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9333 - loss: 0.1493 - val_accuracy: 0.3667 - val_loss: 1.1214\n",
      "Epoch 63/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9333 - loss: 0.1464 - val_accuracy: 0.4000 - val_loss: 1.1069\n",
      "Epoch 64/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9333 - loss: 0.1434 - val_accuracy: 0.4667 - val_loss: 1.0927\n",
      "Epoch 65/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9333 - loss: 0.1406 - val_accuracy: 0.4667 - val_loss: 1.0789\n",
      "Epoch 66/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9333 - loss: 0.1378 - val_accuracy: 0.4667 - val_loss: 1.0654\n",
      "Epoch 67/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9417 - loss: 0.1351 - val_accuracy: 0.4667 - val_loss: 1.0523\n",
      "Epoch 68/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9417 - loss: 0.1324 - val_accuracy: 0.4667 - val_loss: 1.0395\n",
      "Epoch 69/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9583 - loss: 0.1299 - val_accuracy: 0.4667 - val_loss: 1.0272\n",
      "Epoch 70/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9583 - loss: 0.1274 - val_accuracy: 0.4667 - val_loss: 1.0153\n",
      "Epoch 71/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9583 - loss: 0.1249 - val_accuracy: 0.4667 - val_loss: 1.0038\n",
      "Epoch 72/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9583 - loss: 0.1226 - val_accuracy: 0.5000 - val_loss: 0.9926\n",
      "Epoch 73/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9583 - loss: 0.1203 - val_accuracy: 0.5000 - val_loss: 0.9819\n",
      "Epoch 74/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9667 - loss: 0.1181 - val_accuracy: 0.5000 - val_loss: 0.9716\n",
      "Epoch 75/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9667 - loss: 0.1160 - val_accuracy: 0.5000 - val_loss: 0.9617\n",
      "Epoch 76/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9667 - loss: 0.1140 - val_accuracy: 0.5000 - val_loss: 0.9521\n",
      "Epoch 77/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9667 - loss: 0.1120 - val_accuracy: 0.5000 - val_loss: 0.9429\n",
      "Epoch 78/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9667 - loss: 0.1101 - val_accuracy: 0.5000 - val_loss: 0.9341\n",
      "Epoch 79/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9667 - loss: 0.1082 - val_accuracy: 0.5000 - val_loss: 0.9257\n",
      "Epoch 80/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9667 - loss: 0.1065 - val_accuracy: 0.5000 - val_loss: 0.9176\n",
      "Epoch 81/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9667 - loss: 0.1048 - val_accuracy: 0.5000 - val_loss: 0.9098\n",
      "Epoch 82/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9667 - loss: 0.1031 - val_accuracy: 0.5333 - val_loss: 0.9024\n",
      "Epoch 83/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.1015 - val_accuracy: 0.5333 - val_loss: 0.8952\n",
      "Epoch 84/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9750 - loss: 0.1000 - val_accuracy: 0.5333 - val_loss: 0.8884\n",
      "Epoch 85/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.0985 - val_accuracy: 0.5333 - val_loss: 0.8818\n",
      "Epoch 86/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9750 - loss: 0.0971 - val_accuracy: 0.5333 - val_loss: 0.8755\n",
      "Epoch 87/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.0957 - val_accuracy: 0.5333 - val_loss: 0.8695\n",
      "Epoch 88/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9750 - loss: 0.0944 - val_accuracy: 0.5333 - val_loss: 0.8637\n",
      "Epoch 89/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9750 - loss: 0.0931 - val_accuracy: 0.5333 - val_loss: 0.8581\n",
      "Epoch 90/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9750 - loss: 0.0919 - val_accuracy: 0.5333 - val_loss: 0.8528\n",
      "Epoch 91/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9750 - loss: 0.0907 - val_accuracy: 0.5333 - val_loss: 0.8477\n",
      "Epoch 92/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9750 - loss: 0.0896 - val_accuracy: 0.5333 - val_loss: 0.8428\n",
      "Epoch 93/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9750 - loss: 0.0884 - val_accuracy: 0.5667 - val_loss: 0.8381\n",
      "Epoch 94/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9750 - loss: 0.0874 - val_accuracy: 0.6000 - val_loss: 0.8336\n",
      "Epoch 95/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9750 - loss: 0.0863 - val_accuracy: 0.6000 - val_loss: 0.8293\n",
      "Epoch 96/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9750 - loss: 0.0853 - val_accuracy: 0.6333 - val_loss: 0.8252\n",
      "Epoch 97/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9750 - loss: 0.0844 - val_accuracy: 0.6333 - val_loss: 0.8212\n",
      "Epoch 98/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9750 - loss: 0.0834 - val_accuracy: 0.6333 - val_loss: 0.8174\n",
      "Epoch 99/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9750 - loss: 0.0825 - val_accuracy: 0.6333 - val_loss: 0.8137\n",
      "Epoch 100/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9750 - loss: 0.0816 - val_accuracy: 0.6333 - val_loss: 0.8102\n",
      "Epoch 101/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9750 - loss: 0.0808 - val_accuracy: 0.6333 - val_loss: 0.8068\n",
      "Epoch 102/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9750 - loss: 0.0799 - val_accuracy: 0.6333 - val_loss: 0.8035\n",
      "Epoch 103/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9833 - loss: 0.0791 - val_accuracy: 0.6333 - val_loss: 0.8004\n",
      "Epoch 104/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9833 - loss: 0.0783 - val_accuracy: 0.6333 - val_loss: 0.7974\n",
      "Epoch 105/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9833 - loss: 0.0776 - val_accuracy: 0.6333 - val_loss: 0.7945\n",
      "Epoch 106/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9833 - loss: 0.0768 - val_accuracy: 0.6333 - val_loss: 0.7918\n",
      "Epoch 107/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9833 - loss: 0.0761 - val_accuracy: 0.6333 - val_loss: 0.7891\n",
      "Epoch 108/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9833 - loss: 0.0754 - val_accuracy: 0.6333 - val_loss: 0.7866\n",
      "Epoch 109/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9833 - loss: 0.0748 - val_accuracy: 0.6333 - val_loss: 0.7842\n",
      "Epoch 110/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9833 - loss: 0.0741 - val_accuracy: 0.6333 - val_loss: 0.7818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197bbf0d4e0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#add hidden layer\n",
    "model.add(Dense(units=16,activation='relu',kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.1),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=110,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7179a1cf-17c0-4f89-ad73-05d55f9db175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.3780 - loss: 2.6459 - val_accuracy: 0.0000e+00 - val_loss: 2.3822\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3543 - loss: 2.3694 - val_accuracy: 0.0000e+00 - val_loss: 2.1668\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3937 - loss: 2.1634 - val_accuracy: 0.0000e+00 - val_loss: 1.9993\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3701 - loss: 2.1844 - val_accuracy: 0.0000e+00 - val_loss: 1.8575\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3465 - loss: 2.0218 - val_accuracy: 0.0000e+00 - val_loss: 1.7108\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3150 - loss: 2.0629 - val_accuracy: 0.0000e+00 - val_loss: 1.5689\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4016 - loss: 1.7431 - val_accuracy: 0.0000e+00 - val_loss: 1.4682\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3858 - loss: 1.6590 - val_accuracy: 0.0000e+00 - val_loss: 1.3987\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3701 - loss: 1.6677 - val_accuracy: 0.0000e+00 - val_loss: 1.3066\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3622 - loss: 1.6239 - val_accuracy: 0.0000e+00 - val_loss: 1.2282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197cb232190>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed of randomness so that for each run we will get same random behaviour\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "#create model\n",
    "model=Sequential()\n",
    "\n",
    "#add hidden layer with dropout\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(units=32,activation='relu',kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "\n",
    "#create & add Output Layer\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "#model compile(loss,optimizer,metrics)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=.001),metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "model.fit(X,y,batch_size=32,epochs=10,validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a7af6138-fd03-4ffd-99e1-35f42ef268a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "439e9e8e-d4dd-48b8-bc9f-7bec4a878ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step \n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd37f317-6f84-4bfb-8a8e-0355c146a8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fcdc3bbd-b930-4912-b611-d416a8ca29dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05149c86-20b1-412d-b548-f83154225f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1dfb8cad-4678-4e91-b075-6e0ad9cde003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fa720-88a9-43e1-aa74-3b23ed590c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
